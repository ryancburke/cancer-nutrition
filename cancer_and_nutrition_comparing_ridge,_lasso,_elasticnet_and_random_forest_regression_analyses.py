# -*- coding: utf-8 -*-
"""Cancer and nutrition - comparing Ridge, Lasso, ElasticNet and Random Forest Regression analyses.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F5mG8OmABbOAPfJfA7FhMuBcuD6kNZRu
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_csv('Top 5 cancers ASR with Food by category.csv')
df

df1 = df.groupby('Country').apply(lambda group: group.interpolate(method='index'))
df1

# back-fill
df2 = df1.fillna(method='bfill')
df2

# creating lagged variables

import pandas as pd
from pandas import concat
from pandas import DataFrame

landanimal = DataFrame(df2.Land_animal)
dairy = DataFrame(df2.Dairy)
freshfish = DataFrame(df2.Freshwater_fish)
demersalfish = DataFrame(df2.Demersal_fish)
pelagicfish = DataFrame(df2.Pelagic_fish)
crustaceans = DataFrame(df2.Crustaceans)
cephalopods = DataFrame(df2.Cephalopods)
molluscs = DataFrame(df2.Molluscs)
aquaplants = DataFrame(df2.Aquatic_plants)
cereals = DataFrame(df2.Cereals)
starchyroots = DataFrame(df2.Starchy_roots)
sugarsweet = DataFrame(df2.Sugar_sweetener)
pulses = DataFrame(df2.Pulses)
veg = DataFrame(df2.Vegetables)
fruit = DataFrame(df2.Fruits)
alcohol = DataFrame(df2.Alcoholic_beverages)
bovine = DataFrame(df2.Bovine_meat)
sheepgoat = DataFrame(df2.Mutton_goat_meat)
pig = DataFrame(df2.Pig_meat)
poultry = DataFrame(df2.Poultry_meat)
butter = DataFrame(df2.Butter_ghee)
cream = DataFrame(df2.Cream)
eggs = DataFrame(df2.Eggs)
milk = DataFrame(df2.Milk)
seafood = DataFrame(df2.Fish_seafood)
omega3 = DataFrame(df2.Hi_omega3)
omega6 = DataFrame(df2.Hi_omega6)

dataframe = concat([freshfish.shift(20), freshfish.shift(19), freshfish.shift(18), freshfish.shift(17), freshfish.shift(16), freshfish.shift(15), freshfish.shift(14), freshfish.shift(13), freshfish.shift(12), freshfish.shift(11), freshfish.shift(10), freshfish.shift(9), freshfish.shift(8), freshfish.shift(7), freshfish.shift(6), freshfish.shift(5), freshfish.shift(4), freshfish.shift(3), freshfish.shift(2), freshfish.shift(1),
                    demersalfish.shift(20), demersalfish.shift(19), demersalfish.shift(18), demersalfish.shift(17), demersalfish.shift(16), demersalfish.shift(15), demersalfish.shift(14), demersalfish.shift(13), demersalfish.shift(12), demersalfish.shift(11), demersalfish.shift(10), demersalfish.shift(9), demersalfish.shift(8), demersalfish.shift(7), demersalfish.shift(6), demersalfish.shift(5), demersalfish.shift(4), demersalfish.shift(3), demersalfish.shift(2), demersalfish.shift(1),
                    pelagicfish.shift(20), pelagicfish.shift(19), pelagicfish.shift(18), pelagicfish.shift(17), pelagicfish.shift(16), pelagicfish.shift(15), pelagicfish.shift(14), pelagicfish.shift(13), pelagicfish.shift(12), pelagicfish.shift(11), pelagicfish.shift(10), pelagicfish.shift(9), pelagicfish.shift(8), pelagicfish.shift(7), pelagicfish.shift(6), pelagicfish.shift(5), pelagicfish.shift(4), pelagicfish.shift(3), pelagicfish.shift(2), pelagicfish.shift(1),
                    crustaceans.shift(20), crustaceans.shift(19), crustaceans.shift(18), crustaceans.shift(17), crustaceans.shift(16), crustaceans.shift(15), crustaceans.shift(14), crustaceans.shift(13), crustaceans.shift(12), crustaceans.shift(11), crustaceans.shift(10), crustaceans.shift(9), crustaceans.shift(8), crustaceans.shift(7), crustaceans.shift(6), crustaceans.shift(5), crustaceans.shift(4), crustaceans.shift(3), crustaceans.shift(2), crustaceans.shift(1),
                    cephalopods.shift(20), cephalopods.shift(19), cephalopods.shift(18), cephalopods.shift(17), cephalopods.shift(16), cephalopods.shift(15), cephalopods.shift(14), cephalopods.shift(13), cephalopods.shift(12), cephalopods.shift(11), cephalopods.shift(10), cephalopods.shift(9), cephalopods.shift(8), cephalopods.shift(7), cephalopods.shift(6), cephalopods.shift(5), cephalopods.shift(4), cephalopods.shift(3), cephalopods.shift(2), cephalopods.shift(1),
                    molluscs.shift(20), molluscs.shift(19), molluscs.shift(18), molluscs.shift(17), molluscs.shift(16), molluscs.shift(15), molluscs.shift(14), molluscs.shift(13), molluscs.shift(12), molluscs.shift(11), molluscs.shift(10), molluscs.shift(9), molluscs.shift(8), molluscs.shift(7), molluscs.shift(6), molluscs.shift(5), molluscs.shift(4), molluscs.shift(3), molluscs.shift(2), molluscs.shift(1),
                    aquaplants.shift(20), aquaplants.shift(19), aquaplants.shift(18), aquaplants.shift(17), aquaplants.shift(16), aquaplants.shift(15), aquaplants.shift(14), aquaplants.shift(13), aquaplants.shift(12), aquaplants.shift(11), aquaplants.shift(10), aquaplants.shift(9), aquaplants.shift(8), aquaplants.shift(7), aquaplants.shift(6), aquaplants.shift(5), aquaplants.shift(4), aquaplants.shift(3), aquaplants.shift(2), aquaplants.shift(1),
                    cereals.shift(20), cereals.shift(19), cereals.shift(18), cereals.shift(17), cereals.shift(16), cereals.shift(15), cereals.shift(14), cereals.shift(13), cereals.shift(12), cereals.shift(11), cereals.shift(10), cereals.shift(9), cereals.shift(8), cereals.shift(7), cereals.shift(6), cereals.shift(5), cereals.shift(4), cereals.shift(3), cereals.shift(2), cereals.shift(1),
                    starchyroots.shift(20), starchyroots.shift(19), starchyroots.shift(18), starchyroots.shift(17), starchyroots.shift(16), starchyroots.shift(15), starchyroots.shift(14), starchyroots.shift(13), starchyroots.shift(12), starchyroots.shift(11), starchyroots.shift(10), starchyroots.shift(9), starchyroots.shift(8), starchyroots.shift(7), starchyroots.shift(6), starchyroots.shift(5), starchyroots.shift(4), starchyroots.shift(3), starchyroots.shift(2), starchyroots.shift(1),
                    sugarsweet.shift(20), sugarsweet.shift(19), sugarsweet.shift(18), sugarsweet.shift(17), sugarsweet.shift(16), sugarsweet.shift(15), sugarsweet.shift(14), sugarsweet.shift(13), sugarsweet.shift(12), sugarsweet.shift(11), sugarsweet.shift(10), sugarsweet.shift(9), sugarsweet.shift(8), sugarsweet.shift(7), sugarsweet.shift(6), sugarsweet.shift(5), sugarsweet.shift(4), sugarsweet.shift(3), sugarsweet.shift(2), sugarsweet.shift(1), 
                    pulses.shift(20), pulses.shift(19), pulses.shift(18), pulses.shift(17), pulses.shift(16), pulses.shift(15), pulses.shift(14), pulses.shift(13), pulses.shift(12), pulses.shift(11), pulses.shift(10), pulses.shift(9), pulses.shift(8), pulses.shift(7), pulses.shift(6), pulses.shift(5), pulses.shift(4), pulses.shift(3), pulses.shift(2), pulses.shift(1),
                    veg.shift(20), veg.shift(19), veg.shift(18), veg.shift(17), veg.shift(16), veg.shift(15), veg.shift(14), veg.shift(13), veg.shift(12), veg.shift(11), veg.shift(10), veg.shift(9), veg.shift(8), veg.shift(7), veg.shift(6), veg.shift(5), veg.shift(4), veg.shift(3), veg.shift(2), veg.shift(1),
                    fruit.shift(20), fruit.shift(19), fruit.shift(18), fruit.shift(17), fruit.shift(16), fruit.shift(15), fruit.shift(14), fruit.shift(13), fruit.shift(12), fruit.shift(11), fruit.shift(10), fruit.shift(9), fruit.shift(8), fruit.shift(7), fruit.shift(6), fruit.shift(5), fruit.shift(4), fruit.shift(3), fruit.shift(2), fruit.shift(1),
                    alcohol.shift(20), alcohol.shift(19), alcohol.shift(18), alcohol.shift(17), alcohol.shift(16), alcohol.shift(15), alcohol.shift(14), alcohol.shift(13), alcohol.shift(12), alcohol.shift(11), alcohol.shift(10), alcohol.shift(9), alcohol.shift(8), alcohol.shift(7), alcohol.shift(6), alcohol.shift(5), alcohol.shift(4), alcohol.shift(3), alcohol.shift(2), alcohol.shift(1),
                    bovine.shift(20), bovine.shift(19), bovine.shift(18), bovine.shift(17), bovine.shift(16), bovine.shift(15), bovine.shift(14), bovine.shift(13), bovine.shift(12), bovine.shift(11), bovine.shift(10), bovine.shift(9), bovine.shift(8), bovine.shift(7), bovine.shift(6), bovine.shift(5), bovine.shift(4), bovine.shift(3), bovine.shift(2), bovine.shift(1),
                    sheepgoat.shift(20), sheepgoat.shift(19), sheepgoat.shift(18), sheepgoat.shift(17), sheepgoat.shift(16), sheepgoat.shift(15), sheepgoat.shift(14), sheepgoat.shift(13), sheepgoat.shift(12), sheepgoat.shift(11), sheepgoat.shift(10), sheepgoat.shift(9), sheepgoat.shift(8), sheepgoat.shift(7), sheepgoat.shift(6), sheepgoat.shift(5), sheepgoat.shift(4), sheepgoat.shift(3), sheepgoat.shift(2), sheepgoat.shift(1),
                    pig.shift(20), pig.shift(19), pig.shift(18), pig.shift(17), pig.shift(16), pig.shift(15), pig.shift(14), pig.shift(13), pig.shift(12), pig.shift(11), pig.shift(10), pig.shift(9), pig.shift(8), pig.shift(7), pig.shift(6), pig.shift(5), pig.shift(4), pig.shift(3), pig.shift(2), pig.shift(1),
                    poultry.shift(20), poultry.shift(19), poultry.shift(18), poultry.shift(17), poultry.shift(16), poultry.shift(15), poultry.shift(14), poultry.shift(13), poultry.shift(12), poultry.shift(11), poultry.shift(10), poultry.shift(9), poultry.shift(8), poultry.shift(7), poultry.shift(6), poultry.shift(5), poultry.shift(4), poultry.shift(3), poultry.shift(2), poultry.shift(1),
                    landanimal.shift(20), landanimal.shift(19), landanimal.shift(18), landanimal.shift(17), landanimal.shift(16), landanimal.shift(15), landanimal.shift(14), landanimal.shift(13), landanimal.shift(12), landanimal.shift(11), landanimal.shift(10), landanimal.shift(9), landanimal.shift(8), landanimal.shift(7), landanimal.shift(6), landanimal.shift(5), landanimal.shift(4), landanimal.shift(3), landanimal.shift(2), landanimal.shift(1),
                    butter.shift(20), butter.shift(19), butter.shift(18), butter.shift(17), butter.shift(16), butter.shift(15), butter.shift(14), butter.shift(13), butter.shift(12), butter.shift(11), butter.shift(10), butter.shift(9), butter.shift(8), butter.shift(7), butter.shift(6), butter.shift(5), butter.shift(4), butter.shift(3), butter.shift(2), butter.shift(1),
                    cream.shift(20), cream.shift(19), cream.shift(18), cream.shift(17), cream.shift(16), cream.shift(15), cream.shift(14), cream.shift(13), cream.shift(12), cream.shift(11), cream.shift(10), cream.shift(9), cream.shift(8), cream.shift(7), cream.shift(6), cream.shift(5), cream.shift(4), cream.shift(3), cream.shift(2), cream.shift(1),
                    eggs.shift(20), eggs.shift(19), eggs.shift(18), eggs.shift(17), eggs.shift(16), eggs.shift(15), eggs.shift(14), eggs.shift(13), eggs.shift(12), eggs.shift(11), eggs.shift(10), eggs.shift(9), eggs.shift(8), eggs.shift(7), eggs.shift(6), eggs.shift(5), eggs.shift(4), eggs.shift(3), eggs.shift(2), eggs.shift(1),
                    milk.shift(20), milk.shift(19), milk.shift(18), milk.shift(17), milk.shift(16), milk.shift(15), milk.shift(14), milk.shift(13), milk.shift(12), milk.shift(11), milk.shift(10), milk.shift(9), milk.shift(8), milk.shift(7), milk.shift(6), milk.shift(5), milk.shift(4), milk.shift(3), milk.shift(2), milk.shift(1),
                    dairy.shift(20), dairy.shift(19), dairy.shift(18), dairy.shift(17), dairy.shift(16), dairy.shift(15), dairy.shift(14), dairy.shift(13), dairy.shift(12), dairy.shift(11), dairy.shift(10), dairy.shift(9), dairy.shift(8), dairy.shift(7), dairy.shift(6), dairy.shift(5), dairy.shift(4), dairy.shift(3), dairy.shift(2), dairy.shift(1),
                    seafood.shift(20), seafood.shift(19), seafood.shift(18), seafood.shift(17), seafood.shift(16), seafood.shift(15), seafood.shift(14), seafood.shift(13), seafood.shift(12), seafood.shift(11), seafood.shift(10), seafood.shift(9), seafood.shift(8), seafood.shift(7), seafood.shift(6), seafood.shift(5), seafood.shift(4), seafood.shift(3), seafood.shift(2), seafood.shift(1),
                    omega3.shift(20), omega3.shift(19), omega3.shift(18),omega3.shift(17), omega3.shift(16), omega3.shift(15), omega3.shift(14), omega3.shift(13), omega3.shift(12), omega3.shift(11), omega3.shift(10), omega3.shift(9), omega3.shift(8), omega3.shift(7), omega3.shift(6), omega3.shift(5), omega3.shift(4), omega3.shift(3), omega3.shift(2), omega3.shift(1),
                    omega6.shift(20), omega6.shift(19), omega6.shift(18), omega6.shift(17), omega6.shift(16), omega6.shift(15), omega6.shift(14), omega6.shift(13), omega6.shift(12), omega6.shift(11), omega6.shift(10), omega6.shift(9), omega6.shift(8), omega6.shift(7), omega6.shift(6), omega6.shift(5), omega6.shift(4), omega6.shift(3), omega6.shift(2), omega6.shift(1)], axis = 1)
dataframe.columns = ['Freshwater_fish-20','Freshwater_fish-19','Freshwater_fish-18','Freshwater_fish-17','Freshwater_fish-16', 'Freshwater_fish-15', 'Freshwater_fish-14', 'Freshwater_fish-13', 'Freshwater_fish-12', 'Freshwater_fish-11','Freshwater_fish-10','Freshwater_fish-9','Freshwater_fish-8','Freshwater_fish-7','Freshwater_fish-6', 'Freshwater_fish-5', 'Freshwater_fish-4', 'Freshwater_fish-3', 'Freshwater_fish-2', 'Freshwater_fish-1',
                     'Demersal_fish-20','Demersal_fish-19','Demersal_fish-18','Demersal_fish-17','Demersal_fish-16', 'Demersal_fish-15', 'Demersal_fish-14', 'Demersal_fish-13', 'Demersal_fish-12', 'Demersal_fish-11','Demersal_fish-10','Demersal_fish-9','Demersal_fish-8','Demersal_fish-7','Demersal_fish-6', 'Demersal_fish-5', 'Demersal_fish-4', 'Demersal_fish-3', 'Demersal_fish-2', 'Demersal_fish-1',
                     'Pelagic_fish-20','Pelagic_fish-19','Pelagic_fish-18','Pelagic_fish-17','Pelagic_fish-16', 'Pelagic_fish-15', 'Pelagic_fish-14', 'Pelagic_fish-13', 'Pelagic_fish-12', 'Pelagic_fish-11','Pelagic_fish-10','Pelagic_fish-9','Pelagic_fish-8','Pelagic_fish-7','Pelagic_fish-6', 'Pelagic_fish-5', 'Pelagic_fish-4', 'Pelagic_fish-3', 'Pelagic_fish-2', 'Pelagic_fish-1',
                     'Crustaceans-20','Crustaceans-19','Crustaceans-18','Crustaceans-17','Crustaceans-16', 'Crustaceans-15', 'Crustaceans-14', 'Crustaceans-13', 'Crustaceans-12', 'Crustaceans-11','Crustaceans-10','Crustaceans-9','Crustaceans-8','Crustaceans-7','Crustaceans-6', 'Crustaceans-5', 'Crustaceans-4', 'Crustaceans-3', 'Crustaceans-2', 'Crustaceans-1',
                     'Cephalopods-20','Cephalopods-19', 'Cephalopods-18','Cephalopods-17','Cephalopods-16', 'Cephalopods-15', 'Cephalopods-14', 'Cephalopods-13', 'Cephalopods-12', 'Cephalopods-11','Cephalopods-10','Cephalopods-9','Cephalopods-8','Cephalopods-7','Cephalopods-6', 'Cephalopods-5', 'Cephalopods-4', 'Cephalopods-3', 'Cephalopods-2', 'Cephalopods-1', 
                     'Molluscs-20','Molluscs-19','Molluscs-18','Molluscs-17','Molluscs-16', 'Molluscs-15', 'Molluscs-14', 'Molluscs-13', 'Molluscs-12', 'Molluscs-11','Molluscs-10','Molluscs-9','Molluscs-8','Molluscs-7','Molluscs-6', 'Molluscs-5', 'Molluscs-4', 'Molluscs-3', 'Molluscs-2', 'Molluscs-1',
                     'Aquatic_plants-20','Aquatic_plants-19','Aquatic_plants-18','Aquatic_plants-17','Aquatic_plants-16', 'Aquatic_plants-15', 'Aquatic_plants-14', 'Aquatic_plants-13', 'Aquatic_plants-12', 'Aquatic_plants-11','Aquatic_plants-10','Aquatic_plants-9','Aquatic_plants-8','Aquatic_plants-7','Aquatic_plants-6', 'Aquatic_plants-5', 'Aquatic_plants-4', 'Aquatic_plants-3', 'Aquatic_plants-2', 'Aquatic_plants-1',
                     'cereal-20','cereal-19','cereal-18','cereal-17','cereal-16', 'cereal-15', 'cereal-14', 'cereal-13', 'cereal-12', 'cereal-11','cereal-10','cereal-9','cereal-8','cereal-7','cereal-6', 'cereal-5', 'cereal-4', 'cereal-3', 'cereal-2', 'cereal-1', 
                     'starchyroots-20','starchyroots-19','starchyroots-18','starchyroots-17','starchyroots-16', 'starchyroots-15', 'starchyroots-14', 'starchyroots-13', 'starchyroots-12', 'starchyroots-11','starchyroots-10','starchyroots-9','starchyroots-8','starchyroots-7','starchyroots-6', 'starchyroots-5', 'starchyroots-4', 'starchyroots-3', 'starchyroots-2', 'starchyroots-1',
                     'sugarsweet-20','sugarsweet-19','sugarsweet-18','sugarsweet-17','sugarsweet-16', 'sugarsweet-15', 'sugarsweet-14', 'sugarsweet-13', 'sugarsweet-12', 'sugarsweet-11','sugarsweet-10','sugarsweet-9','sugarsweet-8','sugarsweet-7','sugarsweet-6', 'sugarsweet-5', 'sugarsweet-4', 'sugarsweet-3', 'sugarsweet-2', 'sugarsweet-1',
                     'pulses-20','pulses-19','pulses-18','pulses-17','pulses-16', 'pulses-15', 'pulses-14', 'pulses-13', 'pulses-12', 'pulses-11','pulses-10','pulses-9','pulses-8','pulses-7','pulses-6', 'pulses-5', 'pulses-4', 'pulses-3', 'pulses-2', 'pulses-1', 
                     'veg-20','veg-19','veg-18','veg-17','veg-16', 'veg-15', 'veg-14', 'veg-13', 'veg-12', 'veg-11','veg-10','veg-9','veg-8','veg-7','veg-6', 'veg-5', 'veg-4', 'veg-3', 'veg-2', 'veg-1',
                     'fruit-20','fruit-19','fruit-18','fruit-17','fruit-16', 'fruit-15', 'fruit-14', 'fruit-13', 'fruit-12', 'fruit-11','fruit-10','fruit-9','fruit-8','fruit-7','fruit-6', 'fruit-5', 'fruit-4', 'fruit-3', 'fruit-2', 'fruit-1', 
                     'alcohol-20','alcohol-19','alcohol-18','alcohol-17','alcohol-16', 'alcohol-15', 'alcohol-14', 'alcohol-13', 'alcohol-12', 'alcohol-11','alcohol-10','alcohol-9','alcohol-8','alcohol-7','alcohol-6', 'alcohol-5', 'alcohol-4', 'alcohol-3', 'alcohol-2', 'alcohol-1',
                     'bovine-20','bovine-19','bovine-18','bovine-17','bovine-16', 'bovine-15', 'bovine-14', 'bovine-13', 'bovine-12', 'bovine-11','bovine-10','bovine-9','bovine-8','bovine-7','bovine-6', 'bovine-5', 'bovine-4', 'bovine-3', 'bovine-2', 'bovine-1', 
                     'sheepgoat-20','sheepgoat-19','sheepgoat-18','sheepgoat-17','sheepgoat-16', 'sheepgoat-15', 'sheepgoat-14', 'sheepgoat-13', 'sheepgoat-12', 'sheepgoat-11','sheepgoat-10','sheepgoat-9','sheepgoat-8','sheepgoat-7','sheepgoat-6', 'sheepgoat-5', 'sheepgoat-4', 'sheepgoat-3', 'sheepgoat-2', 'sheepgoat-1',
                     'pig-20','pig-19','pig-18','pig-17','pig-16', 'pig-15', 'pig-14', 'pig-13', 'pig-12', 'pig-11','pig-10','pig-9','pig-8','pig-7','pig-6', 'pig-5', 'pig-4', 'pig-3', 'pig-2', 'pig-1', 
                     'poultry-20','poultry-19','poultry-18','poultry-17','poultry-16', 'poultry-15', 'poultry-14', 'poultry-13', 'poultry-12', 'poultry-11','poultry-10','poultry-9','poultry-8','poultry-7','poultry-6', 'poultry-5', 'poultry-4', 'poultry-3', 'poultry-2', 'poultry-1',
                     'landanimal-20', 'landanimal-19', 'landanimal-18', 'landanimal-17', 'landanimal-16', 'landanimal-15', 'landanimal-14', 'landanimal-13', 'landanimal-12', 'landanimal-11', 'landanimal-10', 'landanimal-9', 'landanimal-8', 'landanimal-7', 'landanimal-6', 'landanimal-5', 'landanimal-4', 'landanimal-3', 'landanimal-2', 'landanimal-1',
                     'butter-20','butter-19','butter-18','butter-17','butter-16', 'butter-15', 'butter-14', 'butter-13', 'butter-12', 'butter-11','butter-10','butter-9','butter-8','butter-7','butter-6', 'butter-5', 'butter-4', 'butter-3', 'butter-2', 'butter-1', 
                     'cream-20','cream-19','cream-18','cream-17','cream-16', 'cream-15', 'cream-14', 'cream-13', 'cream-12', 'cream-11','cream-10','cream-9','cream-8','cream-7','cream-6', 'cream-5', 'cream-4', 'cream-3', 'cream-2', 'cream-1',
                     'eggs-20','eggs-19','eggs-18','eggs-17','eggs-16', 'eggs-15', 'eggs-14', 'eggs-13', 'eggs-12', 'eggs-11','eggs-10','eggs-9','eggs-8','eggs-7','eggs-6', 'eggs-5', 'eggs-4', 'eggs-3', 'eggs-2', 'eggs-1', 
                     'milk-20','milk-19','milk-18','milk-17','milk-16', 'milk-15', 'milk-14', 'milk-13', 'milk-12', 'milk-11','milk-10','milk-9','milk-8','milk-7','milk-6', 'milk-5', 'milk-4', 'milk-3', 'milk-2', 'milk-1',
                     'dairy-20', 'dairy-19', 'dairy-18', 'dairy-17', 'dairy-16', 'dairy-15', 'dairy-14', 'dairy-13', 'dairy-12', 'dairy-11', 'dairy-10', 'dairy-9', 'dairy-8', 'dairy-7', 'dairy-6', 'dairy-5', 'dairy-4', 'dairy-3', 'dairy-2', 'dairy-1',
                     'seafood-20','seafood-19','seafood-18','seafood-17','seafood-16', 'seafood-15', 'seafood-14', 'seafood-13', 'seafood-12', 'seafood-11','seafood-10','seafood-9','seafood-8','seafood-7','seafood-6', 'seafood-5', 'seafood-4', 'seafood-3', 'seafood-2', 'seafood-1', 
                     'omega3-20','omega3-19','omega3-18','omega3-17','omega3-16', 'omega3-15', 'omega3-14', 'omega3-13', 'omega3-12', 'omega3-11','omega3-10','omega3-9','omega3-8','omega3-7','omega3-6', 'omega3-5', 'omega3-4', 'omega3-3', 'omega3-2', 'omega3-1',
                     'omega6-20','omega6-19','omega6-18','omega6-17','omega6-16', 'omega6-15', 'omega6-14', 'omega6-13', 'omega6-12', 'omega6-11','omega6-10','omega6-9','omega6-8','omega6-7','omega6-6', 'omega6-5', 'omega6-4', 'omega6-3', 'omega6-2', 'omega6-1']
print(dataframe.head(5))

result = pd.concat([df2, dataframe], axis=1, sort=False)
result

result.head(20)

results = result.dropna()

"""##Visualizing Seafood (and subcategories) and Breast cancer"""

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Breast cancer ASR",
                hue = 'Country', sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Breast cancer ASR",
                hue = 'Regioncat', sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Breast cancer ASR",
                hue = 'Hilo', sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Year", y="seafood-10",
                hue = 'Country', sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Year", y="Breast cancer ASR",
                hue = 'Regioncat', sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Freshwater_fish-10", y="Breast cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Demersal_fish-10", y="Breast cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Pelagic_fish-10", y="Breast cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Crustaceans-10", y="Breast cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Cephalopods-10", y="Breast cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Molluscs-10", y="Breast cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Aquatic_plants-10", y="Breast cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)

sns.scatterplot(x="seafood-10", y="Breast cancer ASR",
                hue="Country", 
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
region = ["North America", "West Europe", "East Europe", "Pacific", "Latin America/Carribean", "Asia"]
sns.scatterplot(x="seafood-10", y="Breast cancer ASR",
                hue="Regioncat", 
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

"""##Visualizing Seafood (and subcategories) and Colorectal cancer"""

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Colorectal cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Colorectal cancer ASR",
                hue = 'Country', sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Colorectal cancer ASR",
                hue = 'Regioncat', sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Colorectal cancer ASR",
                hue = 'Hilo', sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Freshwater_fish-10", y="Colorectal cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Demersal_fish-10", y="Colorectal cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Pelagic_fish-10", y="Colorectal cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Crustaceans-10", y="Colorectal cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Cephalopods-10", y="Colorectal cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Molluscs-10", y="Colorectal cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Aquatic_plants-10", y="Colorectal cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
region = ["North America", "West Europe", "East Europe", "Pacific", "Latin America/Carribean", "Asia"]
sns.scatterplot(x="seafood-10", y="Colorectal cancer ASR",
                hue="Regioncat", 
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

"""##Visualizing Seafood (and subcategories) and Liver cancer"""

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Liver cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Liver cancer ASR",
                hue = 'Country', sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Liver cancer ASR",
                hue = 'Regioncat', sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Liver cancer ASR",
                hue = 'Hilo', sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Freshwater_fish-10", y="Liver cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Demersal_fish-10", y="Liver cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Pelagic_fish-10", y="Liver cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Crustaceans-10", y="Liver cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Cephalopods-10", y="Liver cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Molluscs-10", y="Liver cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Aquatic_plants-10", y="Liver cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
region = ["North America", "West Europe", "East Europe", "Pacific", "Latin America/Carribean", "Asia"]
sns.scatterplot(x="seafood-10", y="Liver cancer ASR",
                hue="Regioncat", 
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

"""##Visualizing Seafood (and subcategories) and Lung cancer"""

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Lung cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Lung cancer ASR",
                hue = 'Country', sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Lung cancer ASR",
                hue = 'Regioncat', sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Lung cancer ASR",
                hue = 'Hilo', sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Freshwater_fish-10", y="Lung cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Demersal_fish-10", y="Lung cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Pelagic_fish-10", y="Lung cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Crustaceans-10", y="Lung cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Cephalopods-10", y="Lung cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Molluscs-10", y="Lung cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Aquatic_plants-10", y="Lung cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
region = ["North America", "West Europe", "East Europe", "Pacific", "Latin America/Carribean", "Asia"]
sns.scatterplot(x="seafood-10", y="Lung cancer ASR",
                hue="Regioncat", 
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

"""##Visualizing Seafood (and subcategories) and Stomach cancer"""

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Stomach cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Stomach cancer ASR",
                hue = "Country", sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="seafood-10", y="Stomach cancer ASR",
                hue = 'Hilo', sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Freshwater_fish-10", y="Stomach cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Demersal_fish-10", y="Stomach cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Pelagic_fish-10", y="Stomach cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Crustaceans-10", y="Stomach cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Cephalopods-10", y="Stomach cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Molluscs-10", y="Stomach cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
sns.scatterplot(x="Aquatic_plants-10", y="Stomach cancer ASR",
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

# Draw a scatter plot while assigning point colors and sizes to different
# variables in the dataset
f, ax = plt.subplots(figsize=(6.5, 6.5))
sns.despine(f, left=True, bottom=True)
region = ["North America", "West Europe", "East Europe", "Pacific", "Latin America/Carribean", "Asia"]
sns.scatterplot(x="seafood-10", y="Stomach cancer ASR",
                hue="Regioncat", 
                sizes=(1, 8), linewidth=0,
                data=results, ax=ax)

"""##Important libraries for Tests"""

# Load libraries
import pandas as pd
from pandas.plotting import scatter_matrix
import matplotlib.pyplot as plt
from sklearn import model_selection
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn import tree

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

# visualisations
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
sns.set_style("whitegrid")
sns.set(rc = {'figure.figsize':(15, 10)})

# udfs ----

# function for creating a feature importance dataframe
def imp_df(column_names, importances):
    df = pd.DataFrame({'feature': column_names,
                       'feature_importance': importances}) \
           .sort_values('feature_importance', ascending = False) \
           .reset_index(drop = True)
    return df

# plotting a feature importance dataframe (horizontal barchart)
def var_imp_plot(imp_df, title):
    imp_df.columns = ['feature', 'feature_importance']
    sns.barplot(x = 'feature_importance', y = 'feature', data = imp_df, orient = 'h', color = 'royalblue') \
       .set_title(title, fontsize = 20)

"""#Predicting Breast cancer incidence using lagged variables"""

from sklearn.ensemble import RandomForestRegressor
# Import train_test_split function
from sklearn.model_selection import train_test_split
X=results[['cereal-10','starchyroots-10', 'sugarsweet-10', 'pulses-10','veg-10','fruit-10','alcohol-10', 'landanimal-10', 'dairy-10', 'eggs-10',
           'seafood-10', 'omega3-10', 'omega6-10']]  # Features

y=results['Breast cancer ASR']  # Labels

# Split dataset into training set and test set
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state = 50) # 70% t

rf = RandomForestRegressor(n_estimators = 100,
                           n_jobs = -1,
                           oob_score = True,
                           bootstrap = True,
                           random_state = 42)
rf.fit(X_train, y_train)

print('R^2 Training Score: {:.2f} \nOOB Score: {:.2f} \nR^2 Validation Score: {:.2f}'.format(rf.score(X_train, y_train), 
                                                                                             rf.oob_score_,
                                                                                             rf.score(X_valid, y_valid)))

sns.heatmap(X.assign(target = y).corr().round(2), cmap = 'Blues', annot = True).set_title('Correlation matrix', fontsize = 16)

pip install rfpimp

pip install eli5

"""##Default feature importance"""

base_imp = imp_df(X_train.columns, rf.feature_importances_)
base_imp

var_imp_plot(base_imp, 'Default feature importance (scikit-learn)')

"""##Permutation feature importance"""

from rfpimp import plot_corr_heatmap
viz = plot_corr_heatmap(X_train, figsize=(15,10))
viz.view()

from sklearn.metrics import r2_score
from rfpimp import permutation_importances

def r2(rf, X_train, y_train):
    return r2_score(y_train, rf.predict(X_train))

perm_imp_rfpimp = permutation_importances(rf, X_train, y_train, r2)
perm_imp_rfpimp.reset_index(drop = False, inplace = True)

var_imp_plot(perm_imp_rfpimp, 'Permutation feature importance (rfpimp)')

"""##Eli5 feature importance"""

import eli5
from eli5.sklearn import PermutationImportance

perm = PermutationImportance(rf, cv = None, refit = False, n_iter = 50).fit(X_train, y_train)
perm_imp_eli5 = imp_df(X_train.columns, perm.feature_importances_)
var_imp_plot(perm_imp_eli5, 'Permutation feature importance (eli5)')

eli5.show_weights(perm)

"""##Drop column feature importance"""

from sklearn.base import clone 

def drop_col_feat_imp(model, X_train, y_train, random_state = 42):
    
    # clone the model to have the exact same specification as the one initially trained
    model_clone = clone(model)
    # set random_state for comparability
    model_clone.random_state = random_state
    # training and scoring the benchmark model
    model_clone.fit(X_train, y_train)
    benchmark_score = model_clone.score(X_train, y_train)
    # list for storing feature importances
    importances = []
    
    # iterating over all columns and storing feature importance (difference between benchmark and new model)
    for col in X_train.columns:
        model_clone = clone(model)
        model_clone.random_state = random_state
        model_clone.fit(X_train.drop(col, axis = 1), y_train)
        drop_col_score = model_clone.score(X_train.drop(col, axis = 1), y_train)
        importances.append(benchmark_score - drop_col_score)
    
    importances_df = imp_df(X_train.columns, importances)
    return importances_df

drop_imp = drop_col_feat_imp(rf, X_train, y_train)
var_imp_plot(drop_imp, 'Drop Column feature importance')

"""##Feature importance using Lime (Local Interpretable Model-agnostic Explanations)"""

pip install lime

import lime
import lime.lime_tabular
import numpy as np

explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,
                                                   mode = 'regression',
                                                   feature_names = X_train.columns,
                                                   discretize_continuous = True)
                                                   
np.random.seed(42)
exp = explainer.explain_instance(X_train.values[31], rf.predict, num_features = 5)
exp.show_in_notebook(show_all=False) #only the features used in the explanation are displayed

exp = explainer.explain_instance(X_train.values[85], rf.predict, num_features = 5)
exp.show_in_notebook(show_all=False)

"""#Predicting Colorectal cancer incidence using lagged variables"""

from sklearn.ensemble import RandomForestRegressor
# Import train_test_split function
from sklearn.model_selection import train_test_split
X=results[['cereal-10','starchyroots-10', 'sugarsweet-10', 'pulses-10','veg-10','fruit-10','alcohol-10', 'landanimal-10', 'dairy-10', 'eggs-10',
           'seafood-10', 'omega3-10', 'omega6-10']]  # Features
           
y=results['Colorectal cancer ASR']  # Labels

# Split dataset into training set and test set
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state = 50) # 70% t

rf = RandomForestRegressor(n_estimators = 100,
                           n_jobs = -1,
                           oob_score = True,
                           bootstrap = True,
                           random_state = 42)
rf.fit(X_train, y_train)

print('R^2 Training Score: {:.2f} \nOOB Score: {:.2f} \nR^2 Validation Score: {:.2f}'.format(rf.score(X_train, y_train), 
                                                                                             rf.oob_score_,
                                                                                             rf.score(X_valid, y_valid)))

pip install rfpimp

pip install eli5

sns.heatmap(X.assign(target = y).corr().round(2), cmap = 'Blues', annot = True).set_title('Correlation matrix', fontsize = 16)

"""##Default feature importance"""

base_imp = imp_df(X_train.columns, rf.feature_importances_)
base_imp

var_imp_plot(base_imp, 'Default feature importance (scikit-learn)')

"""##Permutation feature importance"""

from rfpimp import plot_corr_heatmap
viz = plot_corr_heatmap(X_train, figsize=(15,10))
viz.view()

from sklearn.metrics import r2_score
from rfpimp import permutation_importances

def r2(rf, X_train, y_train):
    return r2_score(y_train, rf.predict(X_train))

perm_imp_rfpimp = permutation_importances(rf, X_train, y_train, r2)
perm_imp_rfpimp.reset_index(drop = False, inplace = True)
var_imp_plot(perm_imp_rfpimp, 'Permutation feature importance (rfpimp)')

"""##Eli5 feature importance"""

import eli5
from eli5.sklearn import PermutationImportance

perm = PermutationImportance(rf, cv = None, refit = False, n_iter = 50).fit(X_train, y_train)
perm_imp_eli5 = imp_df(X_train.columns, perm.feature_importances_)
var_imp_plot(perm_imp_eli5, 'Permutation feature importance (eli5)')

eli5.show_weights(perm)

"""##Drop column feature importance"""

from sklearn.base import clone 

def drop_col_feat_imp(model, X_train, y_train, random_state = 42):
    
    # clone the model to have the exact same specification as the one initially trained
    model_clone = clone(model)
    # set random_state for comparability
    model_clone.random_state = random_state
    # training and scoring the benchmark model
    model_clone.fit(X_train, y_train)
    benchmark_score = model_clone.score(X_train, y_train)
    # list for storing feature importances
    importances = []
    
    # iterating over all columns and storing feature importance (difference between benchmark and new model)
    for col in X_train.columns:
        model_clone = clone(model)
        model_clone.random_state = random_state
        model_clone.fit(X_train.drop(col, axis = 1), y_train)
        drop_col_score = model_clone.score(X_train.drop(col, axis = 1), y_train)
        importances.append(benchmark_score - drop_col_score)
    
    importances_df = imp_df(X_train.columns, importances)
    return importances_df

drop_imp = drop_col_feat_imp(rf, X_train, y_train)
var_imp_plot(drop_imp, 'Drop Column feature importance')

"""##Feature importance using Lime (Local Interpretable Model-agnostic Explanations)"""

pip install lime

import lime
import lime.lime_tabular
import numpy as np

explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,
                                                   mode = 'regression',
                                                   feature_names = X_train.columns,
                                                   discretize_continuous = True)
                                                   
np.random.seed(42)
exp = explainer.explain_instance(X_train.values[31], rf.predict, num_features = 5)
exp.show_in_notebook(show_all=False) #only the features used in the explanation are displayed

exp = explainer.explain_instance(X_train.values[85], rf.predict, num_features = 5)
exp.show_in_notebook(show_all=False)

"""#Predicting liver cancer incidence using lagged nutrition variables"""

from sklearn.ensemble import RandomForestRegressor
# Import train_test_split function
from sklearn.model_selection import train_test_split
X=results[['cereal-10','starchyroots-10', 'sugarsweet-10', 'pulses-10','veg-10','fruit-10','alcohol-10', 'landanimal-10', 'dairy-10', 'eggs-10',
           'seafood-10', 'omega3-10', 'omega6-10']]  # Features
           
y=results['Liver cancer ASR']  # Labels

# Split dataset into training set and test set
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state = 50) # 70% t

rf = RandomForestRegressor(n_estimators = 100,
                           n_jobs = -1,
                           oob_score = True,
                           bootstrap = True,
                           random_state = 42)
rf.fit(X_train, y_train)

print('R^2 Training Score: {:.2f} \nOOB Score: {:.2f} \nR^2 Validation Score: {:.2f}'.format(rf.score(X_train, y_train), 
                                                                                             rf.oob_score_,
                                                                                             rf.score(X_valid, y_valid)))

pip install rfpimp

pip install eli5

sns.heatmap(X.assign(target = y).corr().round(2), cmap = 'Blues', annot = True).set_title('Correlation matrix', fontsize = 16)

"""##Default feature importance"""

base_imp = imp_df(X_train.columns, rf.feature_importances_)
base_imp

var_imp_plot(base_imp, 'Default feature importance (scikit-learn)')

"""##Permutation feature importance"""

from rfpimp import plot_corr_heatmap
viz = plot_corr_heatmap(X_train, figsize=(15,10))
viz.view()

from sklearn.metrics import r2_score
from rfpimp import permutation_importances

def r2(rf, X_train, y_train):
    return r2_score(y_train, rf.predict(X_train))

perm_imp_rfpimp = permutation_importances(rf, X_train, y_train, r2)
perm_imp_rfpimp.reset_index(drop = False, inplace = True)
var_imp_plot(perm_imp_rfpimp, 'Permutation feature importance (rfpimp)')

"""##Eli5 feature importance"""

import eli5
from eli5.sklearn import PermutationImportance

perm = PermutationImportance(rf, cv = None, refit = False, n_iter = 50).fit(X_train, y_train)
perm_imp_eli5 = imp_df(X_train.columns, perm.feature_importances_)
var_imp_plot(perm_imp_eli5, 'Permutation feature importance (eli5)')

eli5.show_weights(perm)

"""##Drop column feature importance"""

from sklearn.base import clone 

def drop_col_feat_imp(model, X_train, y_train, random_state = 42):
    
    # clone the model to have the exact same specification as the one initially trained
    model_clone = clone(model)
    # set random_state for comparability
    model_clone.random_state = random_state
    # training and scoring the benchmark model
    model_clone.fit(X_train, y_train)
    benchmark_score = model_clone.score(X_train, y_train)
    # list for storing feature importances
    importances = []
    
    # iterating over all columns and storing feature importance (difference between benchmark and new model)
    for col in X_train.columns:
        model_clone = clone(model)
        model_clone.random_state = random_state
        model_clone.fit(X_train.drop(col, axis = 1), y_train)
        drop_col_score = model_clone.score(X_train.drop(col, axis = 1), y_train)
        importances.append(benchmark_score - drop_col_score)
    
    importances_df = imp_df(X_train.columns, importances)
    return importances_df

drop_imp = drop_col_feat_imp(rf, X_train, y_train)
var_imp_plot(drop_imp, 'Drop Column feature importance')

"""##Feature importance using Lime (Local Interpretable Model-agnostic Explanations)"""

pip install lime

import lime
import lime.lime_tabular
import numpy as np

explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,
                                                   mode = 'regression',
                                                   feature_names = X_train.columns,
                                                   discretize_continuous = True)
                                                   
np.random.seed(42)
exp = explainer.explain_instance(X_train.values[31], rf.predict, num_features = 5)
exp.show_in_notebook(show_all=False) #only the features used in the explanation are displayed

exp = explainer.explain_instance(X_train.values[85], rf.predict, num_features = 5)
exp.show_in_notebook(show_all=False)

"""#Predicting lung cancer incidence using lagged nutrition variable"""

from sklearn.ensemble import RandomForestRegressor
# Import train_test_split function
from sklearn.model_selection import train_test_split
X=results[['cereal-10','starchyroots-10', 'sugarsweet-10', 'pulses-10','veg-10','fruit-10','alcohol-10', 'landanimal-10', 'dairy-10', 'eggs-10',
           'seafood-10', 'omega3-10', 'omega6-10']]  # Features
           
y=results['Lung cancer ASR']  # Labels

# Split dataset into training set and test set
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state = 50) # 70% t

rf = RandomForestRegressor(n_estimators = 100,
                           n_jobs = -1,
                           oob_score = True,
                           bootstrap = True,
                           random_state = 42)
rf.fit(X_train, y_train)

print('R^2 Training Score: {:.2f} \nOOB Score: {:.2f} \nR^2 Validation Score: {:.2f}'.format(rf.score(X_train, y_train), 
                                                                                             rf.oob_score_,
                                                                                             rf.score(X_valid, y_valid)))

pip install rfpimp

sns.heatmap(X.assign(target = y).corr().round(2), cmap = 'Blues', annot = True).set_title('Correlation matrix', fontsize = 16)

"""##Default feature importance"""

base_imp = imp_df(X_train.columns, rf.feature_importances_)
base_imp

var_imp_plot(base_imp, 'Default feature importance (scikit-learn)')

"""##Permutation feature importance"""

from rfpimp import plot_corr_heatmap
viz = plot_corr_heatmap(X_train, figsize=(15,10))
viz.view()

from sklearn.metrics import r2_score
from rfpimp import permutation_importances

def r2(rf, X_train, y_train):
    return r2_score(y_train, rf.predict(X_train))

perm_imp_rfpimp = permutation_importances(rf, X_train, y_train, r2)
perm_imp_rfpimp.reset_index(drop = False, inplace = True)
var_imp_plot(perm_imp_rfpimp, 'Permutation feature importance (rfpimp)')

"""##Eli5 feature importance"""

pip install eli5

import eli5
from eli5.sklearn import PermutationImportance

perm = PermutationImportance(rf, cv = None, refit = False, n_iter = 50).fit(X_train, y_train)
perm_imp_eli5 = imp_df(X_train.columns, perm.feature_importances_)
var_imp_plot(perm_imp_eli5, 'Permutation feature importance (eli5)')

eli5.show_weights(perm)

"""##Drop column feature importance"""

from sklearn.base import clone 

def drop_col_feat_imp(model, X_train, y_train, random_state = 42):
    
    # clone the model to have the exact same specification as the one initially trained
    model_clone = clone(model)
    # set random_state for comparability
    model_clone.random_state = random_state
    # training and scoring the benchmark model
    model_clone.fit(X_train, y_train)
    benchmark_score = model_clone.score(X_train, y_train)
    # list for storing feature importances
    importances = []
    
    # iterating over all columns and storing feature importance (difference between benchmark and new model)
    for col in X_train.columns:
        model_clone = clone(model)
        model_clone.random_state = random_state
        model_clone.fit(X_train.drop(col, axis = 1), y_train)
        drop_col_score = model_clone.score(X_train.drop(col, axis = 1), y_train)
        importances.append(benchmark_score - drop_col_score)
    
    importances_df = imp_df(X_train.columns, importances)
    return importances_df

drop_imp = drop_col_feat_imp(rf, X_train, y_train)
var_imp_plot(drop_imp, 'Drop Column feature importance')

"""##Feature importance using Lime (Local Interpretable Model-agnostic Explanations)"""

pip install lime

import lime
import lime.lime_tabular
import numpy as np

explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,
                                                   mode = 'regression',
                                                   feature_names = X_train.columns,
                                                   discretize_continuous = True)
                                                   
np.random.seed(42)
exp = explainer.explain_instance(X_train.values[31], rf.predict, num_features = 5)
exp.show_in_notebook(show_all=False) #only the features used in the explanation are displayed

exp = explainer.explain_instance(X_train.values[85], rf.predict, num_features = 5)
exp.show_in_notebook(show_all=False)

"""#Predicting stomach cancer incidence using lagged nutrition variable"""

from sklearn.ensemble import RandomForestRegressor
# Import train_test_split function
from sklearn.model_selection import train_test_split
X=results[['cereal-10','starchyroots-10', 'sugarsweet-10', 'pulses-10','veg-10','fruit-10','alcohol-10', 'landanimal-10', 'dairy-10', 'eggs-10',
           'seafood-10', 'omega3-10', 'omega6-10']]  # Features
           
y=results['Stomach cancer ASR']  # Labels

# Split dataset into training set and test set
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state = 50) # 70% t

rf = RandomForestRegressor(n_estimators = 100,
                           n_jobs = -1,
                           oob_score = True,
                           bootstrap = True,
                           random_state = 42)
rf.fit(X_train, y_train)

print('R^2 Training Score: {:.2f} \nOOB Score: {:.2f} \nR^2 Validation Score: {:.2f}'.format(rf.score(X_train, y_train), 
                                                                                             rf.oob_score_,
                                                                                             rf.score(X_valid, y_valid)))

pip install rfpimp

sns.heatmap(X.assign(target = y).corr().round(2), cmap = 'Blues', annot = True).set_title('Correlation matrix', fontsize = 16)

"""##Default feature importance"""

base_imp = imp_df(X_train.columns, rf.feature_importances_)
base_imp

var_imp_plot(base_imp, 'Default feature importance (scikit-learn)')

"""##Permutation feature importance"""

from rfpimp import plot_corr_heatmap
viz = plot_corr_heatmap(X_train, figsize=(15,10))
viz.view()

from sklearn.metrics import r2_score
from rfpimp import permutation_importances

def r2(rf, X_train, y_train):
    return r2_score(y_train, rf.predict(X_train))

perm_imp_rfpimp = permutation_importances(rf, X_train, y_train, r2)
perm_imp_rfpimp.reset_index(drop = False, inplace = True)
var_imp_plot(perm_imp_rfpimp, 'Permutation feature importance (rfpimp)')

"""##Eli5 feature importance"""

pip install eli5

import eli5
from eli5.sklearn import PermutationImportance

perm = PermutationImportance(rf, cv = None, refit = False, n_iter = 50).fit(X_train, y_train)
perm_imp_eli5 = imp_df(X_train.columns, perm.feature_importances_)
var_imp_plot(perm_imp_eli5, 'Permutation feature importance (eli5)')

eli5.show_weights(perm)

"""##Drop column feature importance"""

from sklearn.base import clone 

def drop_col_feat_imp(model, X_train, y_train, random_state = 42):
    
    # clone the model to have the exact same specification as the one initially trained
    model_clone = clone(model)
    # set random_state for comparability
    model_clone.random_state = random_state
    # training and scoring the benchmark model
    model_clone.fit(X_train, y_train)
    benchmark_score = model_clone.score(X_train, y_train)
    # list for storing feature importances
    importances = []
    
    # iterating over all columns and storing feature importance (difference between benchmark and new model)
    for col in X_train.columns:
        model_clone = clone(model)
        model_clone.random_state = random_state
        model_clone.fit(X_train.drop(col, axis = 1), y_train)
        drop_col_score = model_clone.score(X_train.drop(col, axis = 1), y_train)
        importances.append(benchmark_score - drop_col_score)
    
    importances_df = imp_df(X_train.columns, importances)
    return importances_df

drop_imp = drop_col_feat_imp(rf, X_train, y_train)
var_imp_plot(drop_imp, 'Drop Column feature importance')

"""##Feature importance using Lime (Local Interpretable Model-agnostic Explanations)"""

pip install lime

import lime
import lime.lime_tabular
import numpy as np

explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,
                                                   mode = 'regression',
                                                   feature_names = X_train.columns,
                                                   discretize_continuous = True)
                                                   
np.random.seed(42)
exp = explainer.explain_instance(X_train.values[31], rf.predict, num_features = 5)
exp.show_in_notebook(show_all=False) #only the features used in the explanation are displayed

exp = explainer.explain_instance(X_train.values[85], rf.predict, num_features = 5)
exp.show_in_notebook(show_all=False)

"""#Ridge, Lasso, ElasticNet Regression

##Breast cancer
"""

# Import function to create training and test set splits
from sklearn.model_selection import train_test_split
# Import function to automatically create polynomial features! 
from sklearn.preprocessing import PolynomialFeatures
# Import Linear Regression and a regularized regression function
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LassoCV
# Finally, import function to make a machine learning pipeline
from sklearn.pipeline import make_pipeline

import numpy as np

breast = results.loc[:,[ 'Breast cancer ASR', 'cereal-10','starchyroots-10', 'sugarsweet-10', 'pulses-10','veg-10','fruit-10','alcohol-10', 'landanimal-10', 'dairy-10', 'eggs-10',
           'seafood-10', 'omega3-10', 'omega6-10']]
breast

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

breast_scaled = scaler.fit_transform(breast)
breast_scaled = pd.DataFrame(breast_scaled, columns = [ 'Breast cancer ASR', 'cereal-10','starchyroots-10', 'sugarsweet-10', 'pulses-10','veg-10','fruit-10','alcohol-10', 'landanimal-10', 'dairy-10', 'eggs-10',
           'seafood-10', 'omega3-10', 'omega6-10'] )

breast_scaled.head()

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import sklearn
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
# %matplotlib inline

from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

x = breast.drop('Breast cancer ASR', axis = 1)
y = breast['Breast cancer ASR']
x.head()
y.head()

breast_scaled.shape

train_x, test_x, train_y, test_y, = train_test_split(x, y, test_size=0.3, random_state = 1)
train_x.shape
test_x.shape
train_y.shape
test_y.shape

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn.linear_model import Ridge
from sklearn.linear_model import ElasticNet
lm = LinearRegression()
lm_lasso = Lasso()
lm_ridge = Ridge()
lm_elastic = ElasticNet()
lm
lm_lasso
lm_ridge
lm_elastic

lm.fit(train_x,train_y)
lm_lasso.fit(train_x,train_y)
lm_ridge.fit(train_x,train_y)
lm_elastic.fit(train_x,train_y)

plt.figure(figsize=(15,10))
ft_importances_lm = pd.Series(lm.coef_, index = x.columns)
ft_importances_lm.plot(kind='barh')
plt.show();

plt.figure(figsize=(15,10))
ft_importances_lm_lasso = pd.Series(lm_lasso.coef_, index = x.columns)
ft_importances_lm_lasso.plot(kind='barh')
plt.show();

plt.figure(figsize=(15,10))
ft_importances_lm_ridge = pd.Series(lm_ridge.coef_, index = x.columns)
ft_importances_lm_ridge.plot(kind='barh')
plt.show();

plt.figure(figsize=(15,10))
ft_importances_lm_elastic = pd.Series(lm_elastic.coef_, index = x.columns)
ft_importances_lm_elastic.plot(kind='barh')
plt.show();

print ("RSquare Value for Simple Regression data is-")
np.round(lm.score(test_x,test_y)*100,2)
print ("RSquare Value for Lasso Regression data is-")
np.round(lm_lasso.score(test_x,test_y)*100,2)
print ("RSquare Value for Ridge Regression data is-")
np.round(lm_ridge.score(test_x,test_y)*100,2)
print ("RSquare Value for ElasticNet Regression data is-")
np.round(lm_elastic.score(test_x,test_y)*100,2)

predict_test_lm = lm.predict(test_x)
predict_test_lasso = lm_lasso.predict(test_x)
predict_test_ridge = lm_ridge.predict(test_x)
predict_test_elastic = lm_elastic.predict(test_x)

import numpy as np
from sklearn import metrics
print ("Simple Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_lm),2)
print ("Lasso Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_lasso),2)
print ("Ridge Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_ridge),2)
print ("ElasticNet Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_elastic),2)

"""##Colorectal cancer"""

# Import function to create training and test set splits
from sklearn.model_selection import train_test_split
# Import function to automatically create polynomial features! 
from sklearn.preprocessing import PolynomialFeatures
# Import Linear Regression and a regularized regression function
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LassoCV
# Finally, import function to make a machine learning pipeline
from sklearn.pipeline import make_pipeline

import numpy as np

colorectal = results.loc[:,[ 'Colorectal cancer ASR', 'cereal-10','starchyroots-10', 'sugarsweet-10', 'pulses-10','veg-10','fruit-10','alcohol-10', 'landanimal-10', 'dairy-10', 'eggs-10',
           'seafood-10', 'omega3-10', 'omega6-10']]
colorectal

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

colorectal_scaled = scaler.fit_transform(colorectal)
colorectal_scaled = pd.DataFrame(colorectal_scaled, columns = [ 'Colorectal cancer ASR', 'cereal-10','starchyroots-10', 'sugarsweet-10', 'pulses-10','veg-10','fruit-10','alcohol-10', 'landanimal-10', 'dairy-10', 'eggs-10',
           'seafood-10', 'omega3-10', 'omega6-10'] )

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import sklearn
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
# %matplotlib inline

from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

x = colorectal.drop('Colorectal cancer ASR', axis = 1)
y = colorectal['Colorectal cancer ASR']
x.head()
y.head()

train_x, test_x, train_y, test_y, = train_test_split(x, y, test_size=0.3, random_state = 1)
train_x.shape
test_x.shape
train_y.shape
test_y.shape

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn.linear_model import Ridge
from sklearn.linear_model import ElasticNet
lm = LinearRegression()
lm_lasso = Lasso()
lm_ridge = Ridge()
lm_elastic = ElasticNet()
lm
lm_lasso
lm_ridge
lm_elastic

lm.fit(train_x,train_y)
lm_lasso.fit(train_x,train_y)
lm_ridge.fit(train_x,train_y)
lm_elastic.fit(train_x,train_y)

plt.figure(figsize=(15,10))
ft_importances_lm = pd.Series(lm.coef_, index = x.columns)
ft_importances_lm.plot(kind='barh')
plt.show();

plt.figure(figsize=(15,10))
ft_importances_lm_lasso = pd.Series(lm_lasso.coef_, index = x.columns)
ft_importances_lm_lasso.plot(kind='barh')
plt.show();

plt.figure(figsize=(15,10))
ft_importances_lm_ridge = pd.Series(lm_ridge.coef_, index = x.columns)
ft_importances_lm_ridge.plot(kind='barh')
plt.show();

plt.figure(figsize=(15,10))
ft_importances_lm_elastic = pd.Series(lm_elastic.coef_, index = x.columns)
ft_importances_lm_elastic.plot(kind='barh')
plt.show();

print ("RSquare Value for Simple Regression data is-")
np.round(lm.score(test_x,test_y)*100,2)
print ("RSquare Value for Lasso Regression data is-")
np.round(lm_lasso.score(test_x,test_y)*100,2)
print ("RSquare Value for Ridge Regression data is-")
np.round(lm_ridge.score(test_x,test_y)*100,2)
print ("RSquare Value for ElasticNet Regression data is-")
np.round(lm_elastic.score(test_x,test_y)*100,2)

predict_test_lm = lm.predict(test_x)
predict_test_lasso = lm_lasso.predict(test_x)
predict_test_ridge = lm_ridge.predict(test_x)
predict_test_elastic = lm_elastic.predict(test_x)

import numpy as np
from sklearn import metrics
print ("Simple Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_lm),2)
print ("Lasso Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_lasso),2)
print ("Ridge Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_ridge),2)
print ("ElasticNet Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_elastic),2)

"""##Liver cancer"""

# Import function to create training and test set splits
from sklearn.model_selection import train_test_split
# Import function to automatically create polynomial features! 
from sklearn.preprocessing import PolynomialFeatures
# Import Linear Regression and a regularized regression function
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LassoCV
# Finally, import function to make a machine learning pipeline
from sklearn.pipeline import make_pipeline

import numpy as np

liver = results.loc[:,[ 'Liver cancer ASR', 'cereal-10','starchyroots-10', 'sugarsweet-10', 'pulses-10','veg-10','fruit-10','alcohol-10', 'landanimal-10', 'dairy-10', 'eggs-10',
           'seafood-10', 'omega3-10', 'omega6-10']]
liver

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

liver_scaled = scaler.fit_transform(liver)
liver_scaled = pd.DataFrame(liver_scaled, columns = [ 'Liver cancer ASR', 'cereal-10','starchyroots-10', 'sugarsweet-10', 'pulses-10','veg-10','fruit-10','alcohol-10', 'landanimal-10', 'dairy-10', 'eggs-10',
           'seafood-10', 'omega3-10', 'omega6-10'] )

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import sklearn
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
# %matplotlib inline

from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

x = liver.drop('Liver cancer ASR', axis = 1)
y = liver['Liver cancer ASR']
x.head()
y.head()

train_x, test_x, train_y, test_y, = train_test_split(x, y, test_size=0.3, random_state = 1)
train_x.shape
test_x.shape
train_y.shape
test_y.shape

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn.linear_model import Ridge
from sklearn.linear_model import ElasticNet
lm = LinearRegression()
lm_lasso = Lasso()
lm_ridge = Ridge()
lm_elastic = ElasticNet()
lm
lm_lasso
lm_ridge
lm_elastic

lm.fit(train_x,train_y)
lm_lasso.fit(train_x,train_y)
lm_ridge.fit(train_x,train_y)
lm_elastic.fit(train_x,train_y)

plt.figure(figsize=(15,10))
ft_importances_lm = pd.Series(lm.coef_, index = x.columns)
ft_importances_lm.plot(kind='barh')
plt.show();

plt.figure(figsize=(15,10))
ft_importances_lm_lasso = pd.Series(lm_lasso.coef_, index = x.columns)
ft_importances_lm_lasso.plot(kind='barh')
plt.show();

plt.figure(figsize=(15,10))
ft_importances_lm_ridge = pd.Series(lm_ridge.coef_, index = x.columns)
ft_importances_lm_ridge.plot(kind='barh')
plt.show();

plt.figure(figsize=(15,10))
ft_importances_lm_elastic = pd.Series(lm_elastic.coef_, index = x.columns)
ft_importances_lm_elastic.plot(kind='barh')
plt.show();

print ("RSquare Value for Simple Regression data is-")
np.round(lm.score(test_x,test_y)*100,2)
print ("RSquare Value for Lasso Regression data is-")
np.round(lm_lasso.score(test_x,test_y)*100,2)
print ("RSquare Value for Ridge Regression data is-")
np.round(lm_ridge.score(test_x,test_y)*100,2)
print ("RSquare Value for ElasticNet Regression data is-")
np.round(lm_elastic.score(test_x,test_y)*100,2)

predict_test_lm = lm.predict(test_x)
predict_test_lasso = lm_lasso.predict(test_x)
predict_test_ridge = lm_ridge.predict(test_x)
predict_test_elastic = lm_elastic.predict(test_x)

import numpy as np
from sklearn import metrics
print ("Simple Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_lm),2)
print ("Lasso Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_lasso),2)
print ("Ridge Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_ridge),2)
print ("ElasticNet Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_elastic),2)

"""##Lung cancer"""

# Import function to create training and test set splits
from sklearn.model_selection import train_test_split
# Import function to automatically create polynomial features! 
from sklearn.preprocessing import PolynomialFeatures
# Import Linear Regression and a regularized regression function
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LassoCV
# Finally, import function to make a machine learning pipeline
from sklearn.pipeline import make_pipeline

import numpy as np

lung = results.loc[:,[ 'Lung cancer ASR', 'cereal-10','starchyroots-10', 'sugarsweet-10', 'pulses-10','veg-10','fruit-10','alcohol-10', 'landanimal-10', 'dairy-10', 'eggs-10',
           'seafood-10', 'omega3-10', 'omega6-10']]
lung

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

lung_scaled = scaler.fit_transform(lung)
lung_scaled = pd.DataFrame(lung_scaled, columns = [ 'Lung cancer ASR', 'cereal-10','starchyroots-10', 'sugarsweet-10', 'pulses-10','veg-10','fruit-10','alcohol-10', 'landanimal-10', 'dairy-10', 'eggs-10',
           'seafood-10', 'omega3-10', 'omega6-10'] )

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import sklearn
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
# %matplotlib inline

from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

x = lung.drop('Lung cancer ASR', axis = 1)
y = lung['Lung cancer ASR']
x.head()
y.head()

train_x, test_x, train_y, test_y, = train_test_split(x, y, test_size=0.3, random_state = 1)
train_x.shape
test_x.shape
train_y.shape
test_y.shape

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn.linear_model import Ridge
from sklearn.linear_model import ElasticNet
lm = LinearRegression()
lm_lasso = Lasso()
lm_ridge = Ridge()
lm_elastic = ElasticNet()
lm
lm_lasso
lm_ridge
lm_elastic

lm.fit(train_x,train_y)
lm_lasso.fit(train_x,train_y)
lm_ridge.fit(train_x,train_y)
lm_elastic.fit(train_x,train_y)

plt.figure(figsize=(15,10))
ft_importances_lm = pd.Series(lm.coef_, index = x.columns)
ft_importances_lm.plot(kind='barh')
plt.show();

plt.figure(figsize=(15,10))
ft_importances_lm_lasso = pd.Series(lm_lasso.coef_, index = x.columns)
ft_importances_lm_lasso.plot(kind='barh')
plt.show();

plt.figure(figsize=(15,10))
ft_importances_lm_ridge = pd.Series(lm_ridge.coef_, index = x.columns)
ft_importances_lm_ridge.plot(kind='barh')
plt.show();

plt.figure(figsize=(15,10))
ft_importances_lm_elastic = pd.Series(lm_elastic.coef_, index = x.columns)
ft_importances_lm_elastic.plot(kind='barh')
plt.show();

print ("RSquare Value for Simple Regression data is-")
np.round(lm.score(test_x,test_y)*100,2)
print ("RSquare Value for Lasso Regression data is-")
np.round(lm_lasso.score(test_x,test_y)*100,2)
print ("RSquare Value for Ridge Regression data is-")
np.round(lm_ridge.score(test_x,test_y)*100,2)
print ("RSquare Value for ElasticNet Regression data is-")
np.round(lm_elastic.score(test_x,test_y)*100,2)

predict_test_lm = lm.predict(test_x)
predict_test_lasso = lm_lasso.predict(test_x)
predict_test_ridge = lm_ridge.predict(test_x)
predict_test_elastic = lm_elastic.predict(test_x)

import numpy as np
from sklearn import metrics
print ("Simple Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_lm),2)
print ("Lasso Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_lasso),2)
print ("Ridge Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_ridge),2)
print ("ElasticNet Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_elastic),2)

"""##Stomach cancer"""

# Import function to create training and test set splits
from sklearn.model_selection import train_test_split
# Import function to automatically create polynomial features! 
from sklearn.preprocessing import PolynomialFeatures
# Import Linear Regression and a regularized regression function
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LassoCV
# Finally, import function to make a machine learning pipeline
from sklearn.pipeline import make_pipeline

import numpy as np

stomach = results.loc[:,[ 'Stomach cancer ASR', 'cereal-10','starchyroots-10', 'sugarsweet-10', 'pulses-10','veg-10','fruit-10','alcohol-10', 'landanimal-10', 'dairy-10', 'eggs-10',
           'seafood-10', 'omega3-10', 'omega6-10']]
stomach

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

stomach_scaled = scaler.fit_transform(stomach)
stomach_scaled = pd.DataFrame(stomach_scaled, columns = [ 'Stomach cancer ASR', 'cereal-10','starchyroots-10', 'sugarsweet-10', 'pulses-10','veg-10','fruit-10','alcohol-10', 'landanimal-10', 'dairy-10', 'eggs-10',
           'seafood-10', 'omega3-10', 'omega6-10'] )

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import sklearn
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
# %matplotlib inline

from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

x = stomach_scaled.drop('Stomach cancer ASR', axis = 1)
y = stomach_scaled['Stomach cancer ASR']
x.head()
y.head()

train_x, test_x, train_y, test_y, = train_test_split(x, y, test_size=0.3, random_state = 1)
train_x.shape
test_x.shape
train_y.shape
test_y.shape

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn.linear_model import Ridge
from sklearn.linear_model import ElasticNet
lm = LinearRegression()
lm_lasso = Lasso()
lm_ridge = Ridge()
lm_elastic = ElasticNet()
lm
lm_lasso
lm_ridge
lm_elastic

lm.fit(train_x,train_y)
lm_lasso.fit(train_x,train_y)
lm_ridge.fit(train_x,train_y)
lm_elastic.fit(train_x,train_y)

plt.figure(figsize=(15,10))
ft_importances_lm = pd.Series(lm.coef_, index = x.columns)
ft_importances_lm.plot(kind='barh')
plt.show();

plt.figure(figsize=(15,10))
ft_importances_lm_lasso = pd.Series(lm_lasso.coef_, index = x.columns)
ft_importances_lm_lasso.plot(kind='barh')
plt.show();

plt.figure(figsize=(15,10))
ft_importances_lm_ridge = pd.Series(lm_ridge.coef_, index = x.columns)
ft_importances_lm_ridge.plot(kind='barh')
plt.show();

plt.figure(figsize=(15,10))
ft_importances_lm_elastic = pd.Series(lm_elastic.coef_, index = x.columns)
ft_importances_lm_elastic.plot(kind='barh')
plt.show();

print ("RSquare Value for Simple Regression data is-")
np.round(lm.score(test_x,test_y)*100,2)
print ("RSquare Value for Lasso Regression data is-")
np.round(lm_lasso.score(test_x,test_y)*100,2)
print ("RSquare Value for Ridge Regression data is-")
np.round(lm_ridge.score(test_x,test_y)*100,2)
print ("RSquare Value for ElasticNet Regression data is-")
np.round(lm_elastic.score(test_x,test_y)*100,2)

predict_test_lm = lm.predict(test_x)
predict_test_lasso = lm_lasso.predict(test_x)
predict_test_ridge = lm_ridge.predict(test_x)
predict_test_elastic = lm_elastic.predict(test_x)

import numpy as np
from sklearn import metrics
print ("Simple Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_lm),2)
print ("Lasso Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_lasso),2)
print ("Ridge Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_ridge),2)
print ("ElasticNet Regression Mean Square Error (MSE) for TEST data is")
np.round(metrics.mean_squared_error(test_y,predict_test_elastic),2)